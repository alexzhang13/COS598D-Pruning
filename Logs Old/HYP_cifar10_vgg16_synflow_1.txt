Loading cifar10 dataset.
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
Creating lottery-vgg16 model.
Pre-Train for 0 epochs.
Pruning with synflow for 1 epochs.
Post-Training for 10 epochs.
Train results:
                train_loss  test_loss  top1_accuracy  top5_accuracy
Init.      0          NaN   2.417748          11.71          50.17
Pre-Prune  0          NaN   2.417748          11.71          50.17
Post-Prune 0          NaN   2.302599          10.01          49.83
Final      10    0.519234   0.638074          77.82          98.60
Prune results:
             module   param  ...  score abs sum  prunable
0    layers.0.conv  weight  ...   2.945014e+22      True
1    layers.0.conv    bias  ...   0.000000e+00     False
2    layers.1.conv  weight  ...   2.945054e+22      True
3    layers.1.conv    bias  ...   0.000000e+00     False
4    layers.3.conv  weight  ...   2.944948e+22      True
5    layers.3.conv    bias  ...   0.000000e+00     False
6    layers.4.conv  weight  ...   2.944997e+22      True
7    layers.4.conv    bias  ...   0.000000e+00     False
8    layers.6.conv  weight  ...   2.945032e+22      True
9    layers.6.conv    bias  ...   0.000000e+00     False
10   layers.7.conv  weight  ...   2.944990e+22      True
11   layers.7.conv    bias  ...   0.000000e+00     False
12   layers.8.conv  weight  ...   2.944906e+22      True
13   layers.8.conv    bias  ...   0.000000e+00     False
14  layers.10.conv  weight  ...   2.944808e+22      True
15  layers.10.conv    bias  ...   0.000000e+00     False
16  layers.11.conv  weight  ...   2.944707e+22      True
17  layers.11.conv    bias  ...   0.000000e+00     False
18  layers.12.conv  weight  ...   2.944560e+22      True
19  layers.12.conv    bias  ...   0.000000e+00     False
20  layers.14.conv  weight  ...   2.944373e+22      True
21  layers.14.conv    bias  ...   0.000000e+00     False
22  layers.15.conv  weight  ...   2.944290e+22      True
23  layers.15.conv    bias  ...   0.000000e+00     False
24  layers.16.conv  weight  ...   2.944200e+22      True
25  layers.16.conv    bias  ...   0.000000e+00     False
26              fc  weight  ...   2.944123e+22      True
27              fc    bias  ...   0.000000e+00     False

[28 rows x 13 columns]
Parameter Sparsity: 1475792/14719818 (0.1003)
FLOP Sparsity: 143306916/313478154 (0.4572)
Inference time:  143.41871250304393
Saving results.
